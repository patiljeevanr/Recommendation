{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Recommendation System on Amazon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing header files\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import nltk\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import re\n",
    "from math import sqrt\n",
    "import string\n",
    "import operator\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing review datset for review based recommender\n",
    "reviews_music_df = pd.read_json(\"data/reviews_Digital_Music_5.json\", lines=True)\n",
    "reviews_music_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing rating datset for rating based recommender\n",
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "ratings_music_df = pd.read_csv('data/ratings_Digital_Music.csv', names=header)\n",
    "ratings_music_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Dataset\n",
    "n_users_complete = ratings_music_df.user_id.unique().shape[0]\n",
    "n_items_complete = ratings_music_df.item_id.unique().shape[0]\n",
    "print ('Number of users = ' , str(n_users_complete) , ' | Number of items = ' , str(n_items_complete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsity of Complete Dataset\n",
    "sparsity_complete = round(1.0-len(ratings_music_df)/float(n_users_complete * n_items_complete),3)\n",
    "print ('The sparsity level of Complete Music Dataset is ' ,  str(sparsity_complete*100) , '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 10000 rows\n",
    "ratings_music_df_10000 = ratings_music_df.head(10000)\n",
    "n_users = ratings_music_df_10000.user_id.unique().shape[0]\n",
    "n_items = ratings_music_df_10000.item_id.unique().shape[0]\n",
    "print ('Number of users = ' , str(n_users) , ' | Number of items = ' , str(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsity of first 10000 rows Dataset\n",
    "sparsity_10000 = round(1.0-len(ratings_music_df_10000)/float(n_users*n_items),3)\n",
    "print ('The sparsity level of Music dataset 10000 is ' ,  str(sparsity_10000*100) , '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean for each items (song)\n",
    "ratings_music_df_10000.groupby('item_id')['rating'].mean().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating count for each items (song)\n",
    "ratings_music_df_10000.groupby('item_id')['rating'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean for each items (song) and convert to DataFrame\n",
    "ratings_mean = pd.DataFrame(ratings_music_df_10000.groupby('item_id')['rating'].mean())\n",
    "ratings_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean for each items (song) and convert to DataFrame merge count to it\n",
    "ratings_mean['rating_numbers'] = pd.DataFrame(ratings_music_df_10000.groupby('item_id')['rating'].count())\n",
    "ratings_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort ratings_mean according to ratings_count\n",
    "ratings_mean.sort_values('rating_numbers', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of ratings count\n",
    "ratings_mean['rating_numbers'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of rating\n",
    "ratings_mean['rating'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Plot\n",
    "sns.jointplot(x='rating', y='rating_numbers', data=ratings_mean, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ratings matrix\n",
    "ratings_matrix = ratings_music_df_10000.pivot_table(index='user_id', columns='item_id', values='rating')\n",
    "ratings_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings of that product\n",
    "B00000016W_user_ratings = ratings_matrix['B00000016W']\n",
    "B000000TDH_user_ratings = ratings_matrix['B000000TDH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of the product with matrix\n",
    "similar_to_B00000016W = ratings_matrix.corrwith(B00000016W_user_ratings)\n",
    "similar_to_B000000TDH = ratings_matrix.corrwith(B000000TDH_user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "corr_B00000016W = pd.DataFrame(similar_to_B00000016W, columns=['Correlation'])\n",
    "corr_B00000016W.dropna(inplace=True)\n",
    "corr_B00000016W.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "corr_B000000TDH = pd.DataFrame(similar_to_B000000TDH, columns=['Correlation'])\n",
    "corr_B000000TDH.dropna(inplace=True)\n",
    "corr_B000000TDH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the items, based on correlation\n",
    "corr_B00000016W.sort_values('Correlation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the items, based on correlation\n",
    "corr_B000000TDH.sort_values('Correlation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join ratings count\n",
    "corr_B00000016W = corr_B00000016W.join(ratings_mean['rating_numbers'], how='left', lsuffix='_left', rsuffix='_right')\n",
    "corr_B00000016W.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting based on correlation and subset based on rating_numbers > 100\n",
    "corr_B00000016W[corr_B00000016W['rating_numbers']>100].sort_values('Correlation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join ratings count\n",
    "corr_B000000TDH = corr_B000000TDH.join(ratings_mean['rating_numbers'], how='left', lsuffix='_left', rsuffix='_right')\n",
    "corr_B000000TDH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting based on correlation and subset based on rating_numbers > 100\n",
    "corr_B000000TDH[corr_B000000TDH['rating_numbers']>100].sort_values('Correlation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity based Recommender (cosine, euclidean, manhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only first 10000 rows \n",
    "ratings_music_df_10000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Number of reviewers and number of items\n",
    "n_users = ratings_music_df_10000.user_id.unique().shape[0]\n",
    "n_items = ratings_music_df_10000.item_id.unique().shape[0]\n",
    "print ('Number of users = ' , str(n_users) , ' | Number of items = ' , str(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test split\n",
    "train_data, test_data = cv.train_test_split(ratings_music_df_10000, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test to matrix\n",
    "train_data_matrix = train_data.pivot(index='user_id', columns='item_id', values='rating').fillna(0)\n",
    "test_data_matrix = test_data.pivot(index='user_id', columns='item_id', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity\n",
    "user_similarity_cosine = pairwise_distances(train_data_matrix, n_jobs=-1, metric='cosine')\n",
    "item_similarity_cosine = pairwise_distances(train_data_matrix.T, n_jobs=-1, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate euclidean similarity\n",
    "user_similarity_euclidean = pairwise_distances(train_data_matrix, n_jobs=-1, metric='euclidean')\n",
    "item_similarity_euclidean = pairwise_distances(train_data_matrix.T, n_jobs=-1, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate manhattan similarity\n",
    "user_similarity_manhattan = pairwise_distances(train_data_matrix, n_jobs=-1, metric='manhattan')\n",
    "item_similarity_manhattan = pairwise_distances(train_data_matrix.T, n_jobs=-1, metric='manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        #You use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        #ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        ratings_diff = ratings.sub(ratings.mean(axis=1), axis=0)\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity).div(pd.DataFrame(np.array([np.abs(similarity).sum(axis=1)])).iloc[0]).values\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction using cosine\n",
    "item_prediction_cosine = predict(train_data_matrix, item_similarity_cosine, type='item')\n",
    "user_prediction_cosine = predict(train_data_matrix, user_similarity_cosine, type='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction using euclidean\n",
    "item_prediction_euclidean = predict(train_data_matrix, item_similarity_euclidean, type='item')\n",
    "user_prediction_euclidean = predict(train_data_matrix, user_similarity_euclidean, type='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction using manhattan\n",
    "item_prediction_manhattan = predict(train_data_matrix, item_similarity_manhattan, type='item')\n",
    "user_prediction_manhattan = predict(train_data_matrix, user_similarity_manhattan, type='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the RMSE and MSE\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(ground_truth, prediction))\n",
    "\n",
    "def mse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return mean_squared_error(ground_truth, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('User-based CF (cosine) MSE: ' , str(mse(user_prediction_cosine, test_data_matrix.values)))\n",
    "print ('Item-based CF (cosine) MSE: ' , str(mse(item_prediction_cosine, test_data_matrix.values)))\n",
    "print ('-------------------------------------------------------------------------------------------')\n",
    "print ('User-based CF (euclidean) MSE: ' , str(mse(user_prediction_euclidean, test_data_matrix.values)))\n",
    "print ('Item-based CF (euclidean) MSE: ' , str(mse(item_prediction_euclidean, test_data_matrix.values)))\n",
    "print ('-------------------------------------------------------------------------------------------')\n",
    "print ('User-based CF (manhattan) MSE: ' , str(mse(user_prediction_manhattan, test_data_matrix.values)))\n",
    "print ('Item-based CF (manhattan) MSE: ' , str(mse(item_prediction_manhattan, test_data_matrix.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('User-based CF (cosine) RMSE: ' , str(rmse(user_prediction_cosine, test_data_matrix.values)))\n",
    "print ('Item-based CF (cosine) RMSE: ' , str(rmse(item_prediction_cosine, test_data_matrix.values)))\n",
    "print ('-------------------------------------------------------------------------------------------')\n",
    "print ('User-based CF (euclidean) RMSE: ' , str(rmse(user_prediction_euclidean, test_data_matrix.values)))\n",
    "print ('Item-based CF (euclidean) RMSE: ' , str(rmse(item_prediction_euclidean, test_data_matrix.values)))\n",
    "print ('-------------------------------------------------------------------------------------------')\n",
    "print ('User-based CF (manhattan) RMSE: ' , str(rmse(user_prediction_manhattan, test_data_matrix.values)))\n",
    "print ('Item-based CF (manhattan) RMSE: ' , str(rmse(item_prediction_manhattan, test_data_matrix.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SVD, calculating MSE and RMSE\n",
    "# Get SVD components from train matrix. Choose k.\n",
    "u, s, vt = svds(train_data_matrix, k = 20)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "print ('User-based CF MSE: ' , str(mse(X_pred, test_data_matrix.values)))\n",
    "print ('User-based CF RMSE: ' , str(rmse(X_pred, test_data_matrix.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of user_prediction_cosine\n",
    "columns = [i for i in train_data_matrix]\n",
    "index = list(train_data_matrix.index)\n",
    "usr_pred = pd.DataFrame(user_prediction_cosine, index=index, columns=columns)\n",
    "usr_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended items for Reviewer A10175AMUHOQC4\n",
    "sorted(usr_pred.loc['A10175AMUHOQC4'].to_dict().items(), key=operator.itemgetter(1), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate count and mean of each item ( Song )\n",
    "count = reviews_music_df.groupby(\"asin\", as_index=False).count()\n",
    "mean = reviews_music_df.groupby(\"asin\", as_index=False).mean()\n",
    "\n",
    "dfMerged = pd.merge(reviews_music_df, count, how='right', on=['asin'])\n",
    "dfMerged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "dfMerged[\"totalReviewers\"] = dfMerged[\"reviewerID_y\"]\n",
    "dfMerged[\"overallScore\"] = dfMerged[\"overall_x\"]\n",
    "dfMerged[\"summaryReview\"] = dfMerged[\"summary_x\"]\n",
    "\n",
    "dfNew = dfMerged[['asin','summaryReview','overallScore',\"totalReviewers\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort based on total reviews\n",
    "dfMerged = dfMerged.sort_values(by='totalReviewers', ascending=False)\n",
    "dfCount = dfMerged[dfMerged.totalReviewers >= 50]\n",
    "dfCount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create review summary for each item\n",
    "dfProductReview = reviews_music_df.groupby(\"asin\", as_index=False).mean()\n",
    "ProductReviewSummary = dfCount.groupby(\"asin\")[\"summaryReview\"].apply(list)\n",
    "ProductReviewSummary = pd.DataFrame(ProductReviewSummary)\n",
    "ProductReviewSummary.to_csv(\"ProductReviewSummary.csv\")\n",
    "ProductReviewSummary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean ratings of each product\n",
    "dfProductReview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv and merge the reviews\n",
    "df3 = pd.read_csv(\"ProductReviewSummary.csv\")\n",
    "df3 = pd.merge(df3, dfProductReview, on=\"asin\", how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[['asin','summaryReview','overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for tokenizing summary\n",
    "regEx = re.compile('[^a-z]+')\n",
    "def cleanReviews(reviewText):\n",
    "    reviewText = reviewText.lower()\n",
    "    reviewText = regEx.sub(' ', reviewText).strip()\n",
    "    return reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and drop duplicate rows\n",
    "df3[\"summaryClean\"] = df3[\"summaryReview\"].apply(cleanReviews)\n",
    "df3 = df3.drop_duplicates(['overall'], keep='last')\n",
    "df3 = df3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only reviews\n",
    "reviews = df3[\"summaryClean\"] \n",
    "countVector = CountVectorizer(max_features = 300, stop_words='english') \n",
    "transformedReviews = countVector.fit_transform(reviews) \n",
    "\n",
    "dfReviews = pd.DataFrame(transformedReviews.A, columns=countVector.get_feature_names())\n",
    "dfReviews = dfReviews.astype(int)\n",
    "dfReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv\n",
    "dfReviews.to_csv(\"dfReviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's create a dataset called X\n",
    "X = np.array(dfReviews)\n",
    "# create train and test\n",
    "tpercent = 0.9\n",
    "tsize = int(np.floor(tpercent * len(dfReviews)))\n",
    "dfReviews_train = X[:tsize]\n",
    "dfReviews_test = X[tsize:]\n",
    "#len of train and test\n",
    "lentrain = len(dfReviews_train)\n",
    "lentest = len(dfReviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier to find similar products\n",
    "print(lentrain)\n",
    "print(lentest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm ball_tree\n",
    "neighbor = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(dfReviews_train)\n",
    "\n",
    "# Let's find the k-neighbors of each point in object X. To do that we call the kneighbors() function on object X.\n",
    "distances, indices = neighbor.kneighbors(dfReviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find most related products\n",
    "for i in range(lentest):\n",
    "    a = neighbor.kneighbors([dfReviews_test[i]])\n",
    "    related_product_list = a[1]\n",
    "\n",
    "    first_related_product = [item[0] for item in related_product_list]\n",
    "    first_related_product = str(first_related_product).strip('[]')\n",
    "    first_related_product = int(first_related_product)\n",
    "    second_related_product = [item[1] for item in related_product_list]\n",
    "    second_related_product = str(second_related_product).strip('[]')\n",
    "    second_related_product = int(second_related_product)\n",
    "    \n",
    "    print (\"Based on product reviews, for \", df3[\"asin\"][lentrain + i] ,\" average rating is \",df3[\"overall\"][lentrain + i])\n",
    "    print (\"The first similar product is \", df3[\"asin\"][first_related_product] ,\" average rating is \",df3[\"overall\"][first_related_product])\n",
    "    print (\"The second similar product is \", df3[\"asin\"][second_related_product] ,\" average rating is \",df3[\"overall\"][second_related_product])\n",
    "    print (\"-----------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 3 Neighbours\n",
    "df5_train_target = df3[\"overall\"][:lentrain]\n",
    "df5_test_target = df3[\"overall\"][lentrain:lentrain+lentest]\n",
    "df5_train_target = df5_train_target.astype(int)\n",
    "df5_test_target = df5_test_target.astype(int)\n",
    "\n",
    "n_neighbors = 3\n",
    "knnclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "knnclf.fit(dfReviews_train, df5_train_target)\n",
    "knnpreds_test = knnclf.predict(dfReviews_test)\n",
    "\n",
    "print(classification_report(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (accuracy_score(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 5 Neighbours\n",
    "df5_train_target = df3[\"overall\"][:lentrain]\n",
    "df5_test_target = df3[\"overall\"][lentrain:lentrain+lentest]\n",
    "df5_train_target = df5_train_target.astype(int)\n",
    "df5_test_target = df5_test_target.astype(int)\n",
    "\n",
    "n_neighbors = 5\n",
    "knnclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "knnclf.fit(dfReviews_train, df5_train_target)\n",
    "knnpreds_test = knnclf.predict(dfReviews_test)\n",
    "#print (knnpreds_test)\n",
    "\n",
    "print(classification_report(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (accuracy_score(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test percent changed\n",
    "# First let's create a dataset called X\n",
    "X = np.array(dfReviews)\n",
    " # create train and test\n",
    "tpercent = 0.85\n",
    "tsize = int(np.floor(tpercent * len(dfReviews)))\n",
    "dfReviews_train = X[:tsize]\n",
    "dfReviews_test = X[tsize:]\n",
    "#len of train and test\n",
    "lentrain = len(dfReviews_train)\n",
    "lentest = len(dfReviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will instantiate a nearest neighbor object, and call it nbrs. Then we will fit it to dataset X.\n",
    "neighbor = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(dfReviews_train)\n",
    "\n",
    "# Let's find the k-neighbors of each point in object X. To do that we call the kneighbors() function on object X.\n",
    "distances, indices = neighbor.kneighbors(dfReviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find most related products\n",
    "for i in range(lentest):\n",
    "    a = neighbor.kneighbors([dfReviews_test[i]])\n",
    "    related_product_list = a[1]\n",
    "\n",
    "    first_related_product = [item[0] for item in related_product_list]\n",
    "    first_related_product = str(first_related_product).strip('[]')\n",
    "    first_related_product = int(first_related_product)\n",
    "    second_related_product = [item[1] for item in related_product_list]\n",
    "    second_related_product = str(second_related_product).strip('[]')\n",
    "    second_related_product = int(second_related_product)\n",
    "    \n",
    "    print (\"Based on product reviews, for \", df3[\"asin\"][lentrain + i] ,\" average rating is \",df3[\"overall\"][lentrain + i])\n",
    "    print (\"The first similar product is \", df3[\"asin\"][first_related_product] ,\" average rating is \",df3[\"overall\"][first_related_product])\n",
    "    print (\"The second similar product is \", df3[\"asin\"][second_related_product] ,\" average rating is \",df3[\"overall\"][second_related_product])\n",
    "    print (\"-----------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_train_target = df3[\"overall\"][:lentrain]\n",
    "df5_test_target = df3[\"overall\"][lentrain:lentrain+lentest]\n",
    "df5_train_target = df5_train_target.astype(int)\n",
    "df5_test_target = df5_test_target.astype(int)\n",
    "\n",
    "n_neighbors = 5\n",
    "knnclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "knnclf.fit(dfReviews_train, df5_train_target)\n",
    "knnpreds_test = knnclf.predict(dfReviews_test)\n",
    "#print (knnpreds_test)\n",
    "\n",
    "print(classification_report(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (accuracy_score(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm brute\n",
    "neighbor = NearestNeighbors(n_neighbors=3, algorithm='brute').fit(dfReviews_train)\n",
    "\n",
    "distances, indices = neighbor.kneighbors(dfReviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 3 Neighbours\n",
    "df5_train_target = df3[\"overall\"][:lentrain]\n",
    "df5_test_target = df3[\"overall\"][lentrain:lentrain+lentest]\n",
    "df5_train_target = df5_train_target.astype(int)\n",
    "df5_test_target = df5_test_target.astype(int)\n",
    "n_neighbors = 3\n",
    "knnclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "knnclf.fit(dfReviews_train, df5_train_target)\n",
    "knnpreds_test = knnclf.predict(dfReviews_test)\n",
    "\n",
    "print(classification_report(df5_test_target, knnpreds_test))\n",
    "print (\"Accuracy: \",accuracy_score(df5_test_target, knnpreds_test))\n",
    "print(\"MSE: \",mean_squared_error(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor = NearestNeighbors(n_neighbors=5, algorithm='kd_tree').fit(dfReviews_train)\n",
    "distances, indices = neighbor.kneighbors(dfReviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 5 Neighbours\n",
    "df5_train_target = df3[\"overall\"][:lentrain]\n",
    "df5_test_target = df3[\"overall\"][lentrain:lentrain+lentest]\n",
    "df5_train_target = df5_train_target.astype(int)\n",
    "df5_test_target = df5_test_target.astype(int)\n",
    "n_neighbors = 5\n",
    "knnclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "knnclf.fit(dfReviews_train, df5_train_target)\n",
    "knnpreds_test = knnclf.predict(dfReviews_test)\n",
    "\n",
    "print(classification_report(df5_test_target, knnpreds_test))\n",
    "print (\"Accuracy: \",accuracy_score(df5_test_target, knnpreds_test))\n",
    "print(\"MSE: \",mean_squared_error(df5_test_target, knnpreds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating cluster for wordcloud\n",
    "cluster = reviews_music_df.groupby(\"overall\")[\"summary\"].apply(list)\n",
    "cluster = pd.DataFrame(cluster)\n",
    "cluster.to_csv(\"cluster.csv\")\n",
    "cluster1 = pd.read_csv(\"cluster.csv\")\n",
    "cluster1[\"summaryClean\"] = cluster1[\"summary\"].apply(cleanReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "         \n",
    "        \n",
    "        random_state=1 # chosen at random by flipping a coin; it was heads\n",
    "    ).generate(str(data))\n",
    "    \n",
    "    fig = plt.figure(1, figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(cluster1[\"summaryClean\"][0], title = \"Review Score One\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(cluster1[\"summaryClean\"][1] , title = \"Review Score Two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(cluster1[\"summaryClean\"][2], title = \"Review Score Three\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(cluster1[\"summaryClean\"][3], title = \"Review Score Four\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(cluster1[\"summaryClean\"][4], title = \"Review Score Five\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
